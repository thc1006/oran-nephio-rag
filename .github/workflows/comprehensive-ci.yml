# Advanced CI/CD Pipeline for O-RAN Ã— Nephio RAG System
# Based on 2024 best practices research

name: Comprehensive CI/CD Pipeline

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run nightly tests
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.11'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Code Quality and Security Checks
  code-quality:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12', '3.13']
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for better analysis

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Cache pre-commit environments
      uses: actions/cache@v3
      with:
        path: ~/.cache/pre-commit
        key: pre-commit-${{ matrix.python-version }}-${{ hashFiles('.pre-commit-config.yaml') }}
        restore-keys: |
          pre-commit-${{ matrix.python-version }}-

    - name: Run pre-commit hooks
      run: |
        pre-commit install
        pre-commit run --all-files --show-diff-on-failure

    - name: Security scan with Bandit
      run: |
        bandit -r src/ -f json -o bandit-report.json || true
        bandit -r src/ -f txt

    - name: Upload security scan results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-scan-${{ matrix.python-version }}
        path: bandit-report.json

  # Comprehensive Testing Suite
  test:
    runs-on: ubuntu-latest
    needs: code-quality
    strategy:
      matrix:
        python-version: ['3.9', '3.11', '3.13']
        test-type: ['unit', 'integration', 'performance']
    
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Create test directories
      run: |
        mkdir -p logs
        mkdir -p oran_nephio_vectordb
        mkdir -p embeddings_cache

    - name: Run unit tests
      if: matrix.test-type == 'unit'
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
      run: |
        pytest tests/ -v -m "unit" \
          --cov=src \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --junit-xml=junit-${{ matrix.python-version }}.xml

    - name: Run integration tests
      if: matrix.test-type == 'integration'
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
        REDIS_URL: redis://localhost:6379
      run: |
        pytest tests/ -v -m "integration" \
          --cov=src \
          --cov-append \
          --cov-report=xml \
          --junit-xml=integration-${{ matrix.python-version }}.xml

    - name: Run performance tests
      if: matrix.test-type == 'performance'
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
      run: |
        pytest tests/ -v -m "not slow" --benchmark-only \
          --benchmark-json=benchmark-${{ matrix.python-version }}.json

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}-${{ matrix.test-type }}
        path: |
          junit-*.xml
          integration-*.xml
          benchmark-*.json
          htmlcov/
          coverage.xml

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.test-type == 'unit'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-${{ matrix.python-version }}
        fail_ci_if_error: false

  # Docker Build and Security Scan
  docker-build:
    runs-on: ubuntu-latest
    needs: test
    permissions:
      contents: read
      packages: write
      security-events: write

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        platforms: linux/amd64,linux/arm64
        push: false
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        target: production
        load: true

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results to GitHub Security
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

    - name: Push Docker image
      if: github.event_name == 'push' && github.ref == 'refs/heads/main'
      uses: docker/build-push-action@v5
      with:
        context: .
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        target: production

  # End-to-End Testing
  e2e-test:
    runs-on: ubuntu-latest
    needs: docker-build
    if: github.event_name == 'push'

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: testdb
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Compose
      run: |
        docker-compose -f docker-compose.dev.yml up -d
        sleep 30  # Wait for services to start

    - name: Run E2E tests
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
      run: |
        docker-compose -f docker-compose.dev.yml exec -T oran-rag-app \
          pytest tests/test_e2e.py -v --maxfail=1

    - name: Collect logs
      if: always()
      run: |
        docker-compose -f docker-compose.dev.yml logs > e2e-logs.txt

    - name: Upload E2E artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-artifacts
        path: |
          e2e-logs.txt
          docker-compose.dev.yml

    - name: Cleanup
      if: always()
      run: |
        docker-compose -f docker-compose.dev.yml down -v

  # Performance Benchmarking
  performance-benchmark:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest-benchmark

    - name: Run performance benchmarks
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
      run: |
        pytest tests/ --benchmark-only \
          --benchmark-json=benchmark-results.json \
          --benchmark-sort=mean

    - name: Store benchmark results
      uses: benchmark-action/github-action-benchmark@v1
      with:
        tool: 'pytest'
        output-file-path: benchmark-results.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true

  # Deployment (Production)
  deploy-production:
    runs-on: ubuntu-latest
    needs: [e2e-test, performance-benchmark]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: production

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Deploy to production
      run: |
        echo "Deploying to production..."
        # Add actual deployment steps here
        # Could use kubectl, helm, or other deployment tools

    - name: Post-deployment health check
      run: |
        # Add health check endpoints
        curl -f https://your-production-url/health || exit 1

    - name: Notify deployment
      if: always()
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}

  # Cleanup and Notifications
  cleanup:
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: always()

    steps:
    - name: Clean up artifacts
      run: |
        echo "Cleaning up old artifacts..."

    - name: Generate test report
      run: |
        echo "Generating comprehensive test report..."

    - name: Send notification
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: 'ðŸ”´ CI/CD Pipeline failed. Please check the logs for details.'
          })

# Workflow dispatch for manual runs
  manual-deploy:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch'
    
    steps:
    - name: Manual deployment
      run: |
        echo "Manual deployment triggered"
        # Add manual deployment logic